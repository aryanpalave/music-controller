# Hand Gesture Arpeggiator

Hand-controlled arpeggiator + drum machine + audio reactive visualizer, served as a web app and built with threejs, mediapipe computer vision, rosebud AI, and tone.js.

- Hand #1: controls the arpeggios (raise hand to raise pitch, pinch to change volume)
- Hand #2: controls the drums (raise different fingers to change the pattern)

## Requirements

- Almost any modern web brwoser
- Camera access enabled for hand tracking

## Technologies

- **MediaPipe** | hand tracking and gesture recognition
- **Three.js** |  audio reactive visual rendering
- **Tone.js** | synthesizer sounds
- **HTML5 Canvas** | visual feedback
- **JavaScript** | real-time interaction

## Setup for Development

```bash
# Navigate to the project directory
cd music-controller

# Serve with your preferred method (example using Python)
python3 -m http.server
```

Then open `http://localhost:8000` in your browser.

## License

MIT License

## Credits

- Three.js - https://threejs.org/
- MediaPipe - https://mediapipe.dev/
- Rosebud AI - https://rosebud.ai/
- Tone.js - https://tonejs.github.io/

## Contact

Hi! I'm Aryan, and I love exploring the intersection of music and technology. 

- Email: [aryanpalave108@gmail.com](mailto:aryanpalave108@gmail.com)
- GitHub: [aryanpalave](https://github.com/aryanpalave?tab=repositories)
